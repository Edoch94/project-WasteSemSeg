{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# tensorboard --logdir=\"runs/May18_00-20-34_edoch-ubuntu-xmg./exp/Enet_23-05-18_00-20-33_encoder_Enet_city_(224, 448)_lr_0.0005\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::add_ encountered 84 time(s)\n",
      "Unsupported operator aten::prelu encountered 67 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Unsupported operator aten::max_pool2d_with_indices encountered 2 time(s)\n",
      "Unsupported operator aten::zero_ encountered 2 time(s)\n",
      "Unsupported operator aten::add encountered 31 time(s)\n",
      "Unsupported operator aten::sub encountered 8 time(s)\n",
      "Unsupported operator aten::mul encountered 4 time(s)\n",
      "Unsupported operator aten::max_unpool2d encountered 2 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "decoder.layers.0.dropout, decoder.layers.1.dropout, decoder.layers.2.dropout, decoder.layers.3.dropout, decoder.layers.4.dropout, encoder.bottleneck_1_0.dropout, encoder.bottleneck_1_1.dropout, encoder.bottleneck_1_2.dropout, encoder.bottleneck_1_3.dropout, encoder.bottleneck_1_4.dropout, encoder.bottleneck_2_0.dropout, encoder.bottleneck_2_1.dropout, encoder.bottleneck_2_2.dropout, encoder.bottleneck_2_3.dropout, encoder.bottleneck_2_4.dropout, encoder.bottleneck_2_5.dropout, encoder.bottleneck_2_6.dropout, encoder.bottleneck_2_7.dropout, encoder.bottleneck_2_8.dropout, encoder.bottleneck_3_1.dropout, encoder.bottleneck_3_2.dropout, encoder.bottleneck_3_3.dropout, encoder.bottleneck_3_4.dropout, encoder.bottleneck_3_5.dropout, encoder.bottleneck_3_6.dropout, encoder.bottleneck_3_7.dropout, encoder.bottleneck_3_8.dropout\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12470140928"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "from models.model_ENet import ENet\n",
    "from src.loading_data import loading_data\n",
    "\n",
    "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader, _, _ = loading_data()\n",
    "input_enet = next(iter(train_loader))[0].to(torch_device)\n",
    "\n",
    "model = ENet().to(torch_device)\n",
    "\n",
    "flops = FlopCountAnalysis(model, input_enet)\n",
    "flops.total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::add_ encountered 84 time(s)\n",
      "Unsupported operator aten::prelu encountered 67 time(s)\n",
      "Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
      "Unsupported operator aten::max_pool2d_with_indices encountered 2 time(s)\n",
      "Unsupported operator aten::zero_ encountered 2 time(s)\n",
      "Unsupported operator aten::add encountered 31 time(s)\n",
      "Unsupported operator aten::sub encountered 8 time(s)\n",
      "Unsupported operator aten::mul encountered 4 time(s)\n",
      "Unsupported operator aten::max_unpool2d encountered 2 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "decoder.layers.0.dropout, decoder.layers.1.dropout, decoder.layers.2.dropout, decoder.layers.3.dropout, decoder.layers.4.dropout, encoder.bottleneck_1_0.dropout, encoder.bottleneck_1_1.dropout, encoder.bottleneck_1_2.dropout, encoder.bottleneck_1_3.dropout, encoder.bottleneck_1_4.dropout, encoder.bottleneck_2_0.dropout, encoder.bottleneck_2_1.dropout, encoder.bottleneck_2_2.dropout, encoder.bottleneck_2_3.dropout, encoder.bottleneck_2_4.dropout, encoder.bottleneck_2_5.dropout, encoder.bottleneck_2_6.dropout, encoder.bottleneck_2_7.dropout, encoder.bottleneck_2_8.dropout, encoder.bottleneck_3_1.dropout, encoder.bottleneck_3_2.dropout, encoder.bottleneck_3_3.dropout, encoder.bottleneck_3_4.dropout, encoder.bottleneck_3_5.dropout, encoder.bottleneck_3_6.dropout, encoder.bottleneck_3_7.dropout, encoder.bottleneck_3_8.dropout\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12470140928"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils import save_model_FLOPS\n",
    "\n",
    "save_model_FLOPS(ENet, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363132"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ENet().to(torch_device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "total_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLDL3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
